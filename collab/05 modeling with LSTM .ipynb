{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T05:20:03.431301Z",
     "start_time": "2020-05-27T05:20:03.418984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook contains the complete code to run the test example of modeling the stock market time serie of Microsoft with LSTM neural networks considering the daily observations extrated between 2010 and 2018. The variations of the example are:\n",
    "   \n",
    "   \n",
    "    1. Modeling the time serie only with LSTM.\n",
    "    2. Same model, but adding a signal getting from the sentiment analysis of online news as extra feature in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. First model: modeling the stock market time serie without any extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:14:31.574395Z",
     "start_time": "2020-07-17T00:14:31.558420Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\", font_scale=1.3)\n",
    "sns.set_style('white')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from time import time\n",
    "\n",
    "import matplotlib.ticker as tkr\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "    \n",
    "import math\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The data set _df test 1_ contains the values of the stock market time serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:14:32.568573Z",
     "start_time": "2020-07-17T00:14:32.484106Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data sets/data_to_paper_microsoft_case.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-049b8e0b21f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data sets/data_to_paper_microsoft_case.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# original time serie (Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSFT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/stock_prediction/env/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# 1) try standard library Pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/stock_prediction/env/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data sets/data_to_paper_microsoft_case.pkl'"
     ]
    }
   ],
   "source": [
    "result= pd.read_pickle(\"data sets/data_to_paper_microsoft_case.pkl\")\n",
    "\n",
    "# original time serie (Y)\n",
    "y = result.MSFT.values \n",
    "y = y.astype('float32')\n",
    "y = np.reshape(y, (-1, 1))\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y = scaler.fit_transform(y)\n",
    "\n",
    "\n",
    "\n",
    "# training and testing settings (size)\n",
    "percent_of_training = 0.7\n",
    "train_size = int(len(y) * percent_of_training)\n",
    "test_size = len(y) - train_size\n",
    "# \n",
    "train_y, test_y = y[0:train_size,:], y[train_size:len(y),:]\n",
    "\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T19:16:09.786041Z",
     "start_time": "2020-05-04T19:16:09.781815Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:14:33.335687Z",
     "start_time": "2020-07-17T00:14:33.312459Z"
    }
   },
   "outputs": [],
   "source": [
    "look_back = 7\n",
    "\n",
    "\n",
    "# features of the original time serie (y)\n",
    "X_train_features_1, y_train = create_dataset(train_y, look_back)\n",
    "X_test_features_1, y_test = create_dataset(test_y, look_back)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# join the all the features in one\n",
    "## reshape arrays\n",
    "X_train_features = np.reshape(X_train_features_1, (X_train_features_1.shape[0], 1, X_train_features_1.shape[1]))\n",
    "X_test_features  = np.reshape(X_test_features_1, (X_test_features_1.shape[0], 1, X_test_features_1.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:14:41.125509Z",
     "start_time": "2020-07-17T00:14:33.713940Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(X_train_features.shape[1], X_train_features.shape[2])))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "history = model.fit(X_train_features,y_train, epochs=300, batch_size=25, validation_data=(X_test_features, y_test), \n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=10)], verbose=0, shuffle=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:14:41.600328Z",
     "start_time": "2020-07-17T00:14:41.127798Z"
    }
   },
   "outputs": [],
   "source": [
    "train_predict = model.predict(X_train_features)\n",
    "test_predict  = model.predict(X_test_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train_predict = scaler.inverse_transform(train_predict)\n",
    "#Y_train = scaler.inverse_transform(y_train)\n",
    "#test_predict = scaler.inverse_transform(test_predict)\n",
    "#Y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "print('Train Mean Absolute Error:', mean_absolute_error(np.reshape(y_train,(y_train.shape[0],1)), train_predict[:,0]))\n",
    "print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(np.reshape(y_train,(y_train.shape[0],1)), train_predict[:,0])))\n",
    "print('Test Mean Absolute Error:', mean_absolute_error(np.reshape(y_test,(y_test.shape[0],1)), test_predict[:,0]))\n",
    "print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(np.reshape(y_test,(y_test.shape[0],1)), test_predict[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:14:41.896033Z",
     "start_time": "2020-07-17T00:14:41.602689Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.style.use('seaborn-dark')\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss',color=\"green\")\n",
    "plt.plot(history.history['val_loss'], label='Test Loss',color = \"yellow\")\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:14:42.288156Z",
     "start_time": "2020-07-17T00:14:41.898447Z"
    }
   },
   "outputs": [],
   "source": [
    "time_y_train = pd.DataFrame(data = train_y, index = result[0:train_size].index,columns= [\"\"])\n",
    "time_y_test  = pd.DataFrame(data = test_y, index = result[train_size:].index,columns= [\"\"])\n",
    "\n",
    "time_y_train_prediction = pd.DataFrame(data = train_predict, index = time_y_train[8:].index,columns= [\"\"])\n",
    "time_y_test_prediction  = pd.DataFrame(data = test_predict, index = time_y_test[8:].index,columns= [\"\"])\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(time_y_train,label = \"training\",color =\"green\",marker='.')\n",
    "plt.plot(time_y_test,label = \"test\",marker='.')\n",
    "plt.plot(time_y_train_prediction,color=\"red\",label = \"prediction\")\n",
    "plt.plot(time_y_test_prediction,color=\"red\")\n",
    "plt.title(\"LSTM fit of Microsoft Stock Market Prices\",size = 20)\n",
    "plt.tight_layout()\n",
    "sns.despine(top=True)\n",
    "plt.ylabel('', size=15)\n",
    "plt.xlabel('', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Second model: modeling the stock market time serie with the sentimen analysis of associated online news as extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:15:23.919289Z",
     "start_time": "2020-07-17T00:15:23.864513Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\", font_scale=1.3)\n",
    "sns.set_style('white')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from time import time\n",
    "import matplotlib.ticker as tkr\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "%matplotlib inline\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:16:43.811759Z",
     "start_time": "2020-07-17T00:16:43.716111Z"
    }
   },
   "outputs": [],
   "source": [
    "result= pd.read_pickle(\"data sets/data_to_paper_microsoft_case.pkl\")\n",
    "\n",
    "# original time serie (Y)\n",
    "y = result.MSFT.values #numpy.ndarray\n",
    "y = y.astype('float32')\n",
    "y = np.reshape(y, (-1, 1))\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y = scaler.fit_transform(y)\n",
    "\n",
    "\n",
    "# extra information: features of the sentiment analysis\n",
    "X = result.open.values\n",
    "X = X.astype('float32')\n",
    "X = np.reshape(X, (-1, 1))\n",
    "\n",
    "# training and testing settings (size)\n",
    "percent_of_training = 0.7\n",
    "train_size = int(len(y) * percent_of_training)\n",
    "test_size = len(y) - train_size\n",
    "# \n",
    "train_y, test_y = y[0:train_size,:], y[train_size:len(y),:]\n",
    "train_x, test_x = X[0:train_size,:], X[train_size:len(X),:]\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:16:43.896531Z",
     "start_time": "2020-07-17T00:16:43.868019Z"
    }
   },
   "outputs": [],
   "source": [
    "look_back = 7\n",
    "\n",
    "\n",
    "# features of the original time serie (y)\n",
    "X_train_features_1, y_train = create_dataset(train_y, look_back)\n",
    "X_test_features_1, y_test = create_dataset(test_y, look_back)\n",
    "\n",
    "\n",
    "# calculate extra features in (X)\n",
    "X_train_features_2, auxiliar_1 = create_dataset(train_x, look_back)\n",
    "X_test_features_2, auxiliar_2 = create_dataset(test_x, look_back)\n",
    "\n",
    "\n",
    "# join the all the features in one\n",
    "## reshape arrays\n",
    "X_train_features_1 = np.reshape(X_train_features_1, (X_train_features_1.shape[0], 1, X_train_features_1.shape[1]))\n",
    "X_test_features_1  = np.reshape(X_test_features_1, (X_test_features_1.shape[0], 1, X_test_features_1.shape[1]))\n",
    "X_train_features_2 = np.reshape(X_train_features_2, (X_train_features_2.shape[0], 1, X_train_features_2.shape[1]))\n",
    "X_test_features_2  = np.reshape(X_test_features_2, (X_test_features_2.shape[0], 1, X_test_features_2.shape[1]))\n",
    "## put all together\n",
    "X_train_all_features = np.append(X_train_features_1,X_train_features_2,axis=1)\n",
    "X_test_all_features = np.append(X_test_features_1,X_test_features_2,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:20:24.400967Z",
     "start_time": "2020-07-17T00:20:01.228532Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(X_train_all_features.shape[1], X_train_all_features.shape[2])))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "history = model.fit(X_train_all_features,y_train, epochs=300, batch_size=25, validation_data=(X_test_all_features, y_test), \n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=10)], verbose=0, shuffle=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:20:24.907262Z",
     "start_time": "2020-07-17T00:20:24.403790Z"
    }
   },
   "outputs": [],
   "source": [
    "train_predict = model.predict(X_train_all_features)\n",
    "test_predict  = model.predict(X_test_all_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train_predict = scaler.inverse_transform(train_predict)\n",
    "#Y_train = scaler.inverse_transform(y_train)\n",
    "#test_predict = scaler.inverse_transform(test_predict)\n",
    "#Y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "print('Train Mean Absolute Error:', mean_absolute_error(np.reshape(y_train,(y_train.shape[0],1)), train_predict[:,0]))\n",
    "print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(np.reshape(y_train,(y_train.shape[0],1)), train_predict[:,0])))\n",
    "print('Test Mean Absolute Error:', mean_absolute_error(np.reshape(y_test,(y_test.shape[0],1)), test_predict[:,0]))\n",
    "print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(np.reshape(y_test,(y_test.shape[0],1)), test_predict[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:20:25.185981Z",
     "start_time": "2020-07-17T00:20:24.909792Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.style.use('seaborn-dark')\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss',color=\"green\")\n",
    "plt.plot(history.history['val_loss'], label='Test Loss',color = \"yellow\")\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:20:25.568823Z",
     "start_time": "2020-07-17T00:20:25.188264Z"
    }
   },
   "outputs": [],
   "source": [
    "time_y_train = pd.DataFrame(data = train_y, index = result[0:train_size].index,columns= [\"\"])\n",
    "time_y_test  = pd.DataFrame(data = test_y, index = result[train_size:].index,columns= [\"\"])\n",
    "\n",
    "time_y_train_prediction = pd.DataFrame(data = train_predict, index = time_y_train[8:].index,columns= [\"\"])\n",
    "time_y_test_prediction  = pd.DataFrame(data = test_predict, index = time_y_test[8:].index,columns= [\"\"])\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(time_y_train,label = \"training\",color =\"green\",marker='.')\n",
    "plt.plot(time_y_test,label = \"test\",marker='.')\n",
    "plt.plot(time_y_train_prediction,color=\"red\",label = \"prediction\")\n",
    "plt.plot(time_y_test_prediction,color=\"red\")\n",
    "plt.title(\"LSTM fit of Microsoft Stock Market Prices Including Sentiment Signal\",size = 20)\n",
    "plt.tight_layout()\n",
    "sns.despine(top=True)\n",
    "plt.ylabel('', size=15)\n",
    "plt.xlabel('', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
